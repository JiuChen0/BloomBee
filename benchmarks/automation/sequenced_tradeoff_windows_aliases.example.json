{
  "host_defaults": {
    "repo_dir": "/root/BloomBee",
    "activate": "",
    "ssh_options": [
      "BatchMode=yes",
      "StrictHostKeyChecking=accept-new",
      "ServerAliveInterval=30",
      "ServerAliveCountMax=120"
    ]
  },
  "hosts": {
    "dht": {
      "host": "merced",
      "repo_dir": "/home/charlie/BloomBee"
    },
    "server1": {
      "host": "Canada4090"
    },
    "server2": {
      "host": "NewJersey4090"
    },
    "client": {
      "host": "NewJersey4090"
    }
  },
  "schedule": {
    "wait_after_dht_sec": 30,
    "wait_after_server1_sec": 30,
    "wait_after_server2_sec": 30,
    "teardown_wait_sec": 3,
    "inter_case_sec": 15,
    "client_timeout_sec": 21600,
    "reinstall_editable_each_case": true,
    "reinstall_roles": [
      "dht",
      "server1",
      "server2",
      "client"
    ],
    "reinstall_cmd": "pip install -e .",
    "reinstall_timeout_sec": 3600,
    "results_root": "/tmp/bb_sensitivity_runs",
    "run_tag": "tradeoff_weekly"
  },
  "shared_vars": {
    "model": "huggyllama/llama-13b",
    "bbserver": "/ip4/169.236.184.234/tcp/31340/p2p/QmRDC1ahoyUvHFPo2CTqrHjiGUH5fji32eHEEgmnvNrE9R",
    "torch_dtype": "float32",
    "max_batch_size": 22288
  },
  "commands": {
    "dht": "python -m bloombee.cli.run_dht --host_maddrs /ip4/0.0.0.0/tcp/31340 --announce_maddrs /ip4/169.236.184.234/tcp/31340 --identity_path bootstrapp1.id",
    "server1": "CUDA_VISIBLE_DEVICES=0 python -m bloombee.cli.run_server {model} --initial_peers {bbserver} --block_indices 0:20 --identity_path serverNorway.id --public_name nodeNorway --host_maddrs /ip4/0.0.0.0/tcp/53749 --announce_maddrs /ip4/142.112.39.215/tcp/42597 --batch_size {batch_size} --max_batch_size {max_batch_size}",
    "server2": "CUDA_VISIBLE_DEVICES=0 python -m bloombee.cli.run_server {model} --initial_peers {bbserver} --block_indices 20:40 --identity_path serverNorway.id --public_name nodeNorway --host_maddrs /ip4/0.0.0.0/tcp/50560 --announce_maddrs /ip4/71.104.167.14/tcp/50560 --batch_size {batch_size} --max_batch_size {max_batch_size}",
    "client": "python benchmarks/benchmark_inference.py --model {model} --initial_peers {bbserver} --torch_dtype {torch_dtype} --seq_len {seq_len} --batch_size {batch_size} --eval_tokens {eval_tokens}"
  },
  "default_env": {
    "all": {
      "BBSERVER": "{bbserver}",
      "BLOOMBEE_LOSSLESS_ALGO": "zstd",
      "BLOOMBEE_LOSSLESS_LEVEL": "3",
      "BLOOMBEE_LOSSLESS_MIN_BYTES": "49152",
      "BLOOMBEE_POLICY_W_GPU_PERCENT": "{policy_w_gpu_percent}",
      "BLOOMBEE_POLICY_W_CPU_PERCENT": "{policy_w_cpu_percent}",
      "BLOOMBEE_POLICY_CACHE_GPU_PERCENT": "{policy_cache_gpu_percent}",
      "BLOOMBEE_POLICY_CACHE_CPU_PERCENT": "{policy_cache_cpu_percent}",
      "BLOOMBEE_POLICY_ACT_GPU_PERCENT": "{policy_act_gpu_percent}",
      "BLOOMBEE_POLICY_ACT_CPU_PERCENT": "{policy_act_cpu_percent}"
    }
  },
  "cases": [
    {
      "name": "bs24_mb8_off1_cmp0",
      "vars": {
        "batch_size": 24,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 8,
        "microbatch_enabled": 1,
        "offload": 1,
        "lossless_wrapper": 0
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs24_mb8_off1_cmp1",
      "vars": {
        "batch_size": 24,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 8,
        "microbatch_enabled": 1,
        "offload": 1,
        "lossless_wrapper": 1
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs24_off0_cmp0",
      "vars": {
        "batch_size": 24,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 0,
        "microbatch_enabled": 0,
        "offload": 0,
        "lossless_wrapper": 0
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs24_off0_cmp1",
      "vars": {
        "batch_size": 24,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 0,
        "microbatch_enabled": 0,
        "offload": 0,
        "lossless_wrapper": 1
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs84_mb8_off1_cmp0",
      "vars": {
        "batch_size": 84,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 8,
        "microbatch_enabled": 1,
        "offload": 1,
        "lossless_wrapper": 0
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs84_mb8_off1_cmp1",
      "vars": {
        "batch_size": 84,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 8,
        "microbatch_enabled": 1,
        "offload": 1,
        "lossless_wrapper": 1
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs84_off0_cmp0",
      "vars": {
        "batch_size": 84,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 0,
        "microbatch_enabled": 0,
        "offload": 0,
        "lossless_wrapper": 0
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    },
    {
      "name": "bs84_off0_cmp1",
      "vars": {
        "batch_size": 84,
        "seq_len": 512,
        "eval_tokens": 200,
        "micro_batch_size": 0,
        "microbatch_enabled": 0,
        "offload": 0,
        "lossless_wrapper": 1
      },
      "env": {
        "all": {
          "BLOOMBEE_ENABLE_KV_OFFLOAD": "{offload}",
          "BLOOMBEE_LOSSLESS_WRAPPER": "{lossless_wrapper}"
        },
        "server1": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "server2": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        },
        "client": {
          "BLOOMBEE_ENABLE_MICROBATCH_PIPELINE": "{microbatch_enabled}",
          "BLOOMBEE_MICRO_BATCH_SIZE": "{micro_batch_size}"
        }
      }
    }
  ]
}
